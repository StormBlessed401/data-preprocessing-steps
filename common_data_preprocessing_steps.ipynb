{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QywdpopIBvY0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Load the CSV file\n",
        "df = pd.read_csv(\"your_file.csv\")  # Replace with actual filename\n",
        "\n",
        "# 2. Basic inspection\n",
        "print(df.head())           # View first 5 rows\n",
        "print(df.info())           # See column types and non-null counts\n",
        "print(df.describe())       # Summary stats for numerical columns\n",
        "\n",
        "# 3. Handle missing values\n",
        "print(df.isnull().sum())   # Check for missing values in each column\n",
        "\n",
        "# Fill missing values for a specific column (e.g., 'age') with mean\n",
        "df['age'].fillna(df['age'].mean(), inplace=True)\n",
        "# `inplace=True` means the change is made directly to `df` without needing to reassign it\n",
        "\n",
        "# OR: Drop rows with any missing values (use with caution)\n",
        "# df.dropna(inplace=True)\n",
        "\n",
        "# 4. Remove duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# 5. Rename a column\n",
        "df.rename(columns={'OldColumnName': 'NewColumnName'}, inplace=True)\n",
        "\n",
        "# 6. Change data types\n",
        "# Convert a column to datetime (if it's a date stored as string)\n",
        "df['date_column'] = pd.to_datetime(df['date_column'])\n",
        "\n",
        "# Convert a numerical column to string (useful in some cases)\n",
        "df['id'] = df['id'].astype(str)\n",
        "\n",
        "# 7. Encode categorical columns\n",
        "le = LabelEncoder()\n",
        "df['gender_encoded'] = le.fit_transform(df['gender'])  # Converts 'male', 'female' to 0, 1\n",
        "\n",
        "# OR use one-hot encoding (converts categories into separate 0/1 columns)\n",
        "df = pd.get_dummies(df, columns=['city'], drop_first=True)\n",
        "# drop_first=True avoids the dummy variable trap by dropping one of the categories\n",
        "\n",
        "# 8. Text preprocessing (e.g., cleaning up a review column)\n",
        "df['review'] = df['review'].str.lower()  # convert to lowercase\n",
        "df['review'] = df['review'].str.replace(r'[^a-zA-Z]', ' ', regex=True)  # remove non-alphabet characters\n",
        "df['review'] = df['review'].str.replace(r'\\s+', ' ', regex=True).str.strip()  # remove extra whitespace\n",
        "\n",
        "# 9. Feature scaling / normalization\n",
        "# Scaling is usually applied only to numerical features, not to categorical or text columns\n",
        "\n",
        "# Extract only the numerical columns you want to scale\n",
        "numerical_cols = ['salary', 'experience']  # example numeric columns\n",
        "scaler = StandardScaler()\n",
        "\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "#  What is Scaling?\n",
        "# Scaling transforms your numeric data to have a mean of 0 and standard deviation of 1.\n",
        "# This is especially important for algorithms like KNN, SVM, etc., which are sensitive to the scale of data.\n",
        "\n",
        "#  What is Normalization?\n",
        "# Normalization generally means converting values into a [0, 1] range (MinMaxScaler does this).\n",
        "# Use StandardScaler for \"standardizing\" (mean=0, std=1), and MinMaxScaler for \"normalizing\".\n",
        "\n",
        "# 10. Train-Test Split\n",
        "X = df.drop('target', axis=1)  # 'target' is the column you're trying to predict\n",
        "y = df['target']\n",
        "\n",
        "# Split into training and test sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 11. Save the cleaned data to a new CSV file\n",
        "df.to_csv(\"cleaned_dataset.csv\", index=False)\n",
        "# `index=False` means the DataFrame index (row numbers) won't be saved as a column in the CSV\n"
      ]
    }
  ]
}


# Problem 1
# Apply all the preprocessing techniques that you think are necessary
import pandas as pd
import re
import string
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

df=pd.read_csv("IMDB Dataset.csv")
df.head()


def clean_text(text):
    text = text.lower()                                # Lowercase
    text = re.sub(r'\d+', '', text)                    # Remove numbers
    text = re.sub(r"http\S+|www\S+", "", text)         # remove links
    text = re.sub(r"<[^>]+>", "", text)                 # remove html tags
    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation
    text = re.sub(r'\s+', ' ', text).strip()           # Remove extra whitespace
    words = text.split()
    words = [w for w in words if w not in stop_words]  # Remove stopwords
    return ' '.join(words)

# Apply cleaning function
df['CleanReview'] = df['review'].apply(clean_text)
# creating new csv file with the two columns
df[['CleanReview', 'sentiment']].to_csv("cleaned_movie_data.csv", index=False)


# Preview
print(df[['CleanReview', 'sentiment']])
